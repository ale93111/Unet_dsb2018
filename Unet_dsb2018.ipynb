{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_dsb2018.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ale93111/Unet_dsb2018/blob/master/Unet_dsb2018.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "4jyO_Z7kSmG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "9b58e3f2-d382-42aa-8e63-8e83e304141b"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b1hZOYGKSoqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa7267b7-4e62-47dc-e618-fef3c32c15ae"
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eKr1IR2kSqGi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c089cea4-b561-4474-94dc-84701ab90f7c"
      },
      "cell_type": "code",
      "source": [
        "#!fusermount -u drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "import os\n",
        "os.chdir(\"drive/kaggle/Unet_dsb2018\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\r\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HvHexk_dSrwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "66d4634d-8d3f-41bc-fc03-a175d618e481"
      },
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade pip\n",
        "!pip install tqdm\n",
        "!pip install keras\n",
        "!pip install imgaug"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages\n",
            "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.11.0->imgaug)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image>=0.11.0->imgaug)\n",
            "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iNa6A6mFUMHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8ecd4d0-14bb-49a8-9f1e-761f04d8d3ed"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "\n",
        "print(ROOT_DIR)\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "#Dataset directory\n",
        "dataset_path = os.path.join(ROOT_DIR, \"RCNN_dataset_512_labels\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/kaggle/Unet_dsb2018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NWW13t-KNB-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "411f4e88-3573-4489-d4a7-2ce03c79c6ed"
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import skimage.io\n",
        "import numpy as np\n",
        "\n",
        "#Find paths and load images and labels(=compressed masks)\n",
        "img_paths = sorted(glob.glob(os.path.join(dataset_path,\"*.png\")))\n",
        "msk_paths = sorted(glob.glob(os.path.join(dataset_path,\"*.npy\")))\n",
        "\n",
        "print(\"Loading images...\")\n",
        "img_list = list(skimage.io.imread_collection(img_paths))\n",
        "print(\"Loading labels...\")\n",
        "lab_list = [np.load(_path) for _path in msk_paths]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading images...\n",
            "Loading labels...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_7iJoNa4NOA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29a7457c-c2a7-450c-8fee-f76d9eb58b0b"
      },
      "cell_type": "code",
      "source": [
        "from scipy.ndimage.morphology import binary_erosion\n",
        "from tqdm import tqdm\n",
        "\n",
        "def label_to_masks(labels):\n",
        "    h, w = labels.shape\n",
        "    n_msk = labels.max()\n",
        "    masks = np.empty((h,w,n_msk),dtype=np.bool)\n",
        "    for i in range(n_msk):\n",
        "        masks[:,:,i] = labels==i+1\n",
        "    return masks\n",
        "  \n",
        "def masks_to_label(msk):\n",
        "    h, w, _ = msk.shape\n",
        "    labels = np.zeros((h, w), dtype=np.uint16)\n",
        "    for index in range(0, msk.shape[-1]):\n",
        "        labels[msk[:,:,index] > 0] = index + 1\n",
        "    return labels\n",
        "  \n",
        "def masks_to_gt(msk):\n",
        "    h, w, _ = msk.shape\n",
        "    gt = np.zeros((h, w), dtype=np.bool)\n",
        "    for index in range(0, msk.shape[-1]):\n",
        "        gt[msk[:,:,index] > 0] = True\n",
        "    return gt[:,:,np.newaxis]\n",
        "  \n",
        "\n",
        "gt_list = []\n",
        "for i,label in tqdm(enumerate(lab_list), total=len(lab_list)):\n",
        "    #Convert to masks\n",
        "    masks = label_to_masks(label)\n",
        "    \n",
        "    #Mask erosion as preprocessing\n",
        "    for j in range(masks.shape[-1]):\n",
        "        masks[:,:,j] = binary_erosion(masks[:,:,j].astype(np.uint8), border_value=1, iterations=1)\n",
        "    masks = masks.astype(np.bool)\n",
        "    \n",
        "    #Get ground truths\n",
        "    gt_list.append(masks_to_gt(masks))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 809/809 [04:39<00:00,  2.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PNlLqzO0RDwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a241ea5-5c37-447d-c830-7226e3cb1eec"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import keras.layers as KL\n",
        "import keras.models as KM\n",
        "import keras.utils as KU\n",
        "import keras.losses as KLO\n",
        "\n",
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2, y_true)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0) #AGGIUNTO AXIS=0\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return 0.5 * KLO.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n",
        "  \n",
        "def Unet(img_size, GPU_COUNT=1):\n",
        "    inputs = KL.Input((None, None, 3))\n",
        "    s = KL.Lambda(lambda x: x / 255.0)(inputs)\n",
        "\n",
        "    #TODO: make more general\n",
        "    c1 = KL.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(s)\n",
        "    n1 = KL.BatchNormalization(axis=3)(c1)\n",
        "    a1 = KL.Activation(\"elu\")(n1)\n",
        "    c1 = KL.Dropout(0.2)(a1)\n",
        "    c1 = KL.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(c1)\n",
        "    n1 = KL.BatchNormalization(axis=3)(c1)\n",
        "    a1 = KL.Activation(\"elu\")(n1)\n",
        "    p1 = KL.MaxPooling2D((2, 2))(a1)\n",
        "\n",
        "    c2 = KL.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(p1)\n",
        "    n2 = KL.BatchNormalization(axis=3)(c2)\n",
        "    a2 = KL.Activation(\"elu\")(n2)\n",
        "    c2 = KL.Dropout(0.2)(a2)\n",
        "    c2 = KL.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c2)\n",
        "    n2 = KL.BatchNormalization(axis=3)(c2)\n",
        "    a2 = KL.Activation(\"elu\")(n2)\n",
        "    p2 = KL.MaxPooling2D((2, 2))(a2)\n",
        "\n",
        "    c3 = KL.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(p2)\n",
        "    n3 = KL.BatchNormalization(axis=3)(c3)\n",
        "    a3 = KL.Activation(\"elu\")(n3)\n",
        "    c3 = KL.Dropout(0.3)(a3)\n",
        "    c3 = KL.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c3)\n",
        "    n3 = KL.BatchNormalization(axis=3)(c3)\n",
        "    a3 = KL.Activation(\"elu\")(n3)\n",
        "    p3 = KL.MaxPooling2D((2, 2))(a3)\n",
        "\n",
        "    c4 = KL.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(p3)\n",
        "    n4 = KL.BatchNormalization(axis=3)(c4)\n",
        "    a4 = KL.Activation(\"elu\")(n4)\n",
        "    c4 = KL.Dropout(0.4)(a4)\n",
        "    c4 = KL.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c4)\n",
        "    n4 = KL.BatchNormalization(axis=3)(c4)\n",
        "    a4 = KL.Activation(\"elu\")(n4)\n",
        "    p4 = KL.MaxPooling2D(pool_size=(2, 2))(a4)\n",
        "\n",
        "    c5 = KL.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(p4)\n",
        "    n5 = KL.BatchNormalization(axis=3)(c5)\n",
        "    a5 = KL.Activation(\"elu\")(n5)\n",
        "    c5 = KL.Dropout(0.4)(a5)\n",
        "    c5 = KL.Conv2D(512, (3, 3), kernel_initializer='he_normal', padding='same')(c5)\n",
        "    n5 = KL.BatchNormalization(axis=3)(c5)\n",
        "    a5 = KL.Activation(\"elu\")(n5)\n",
        "\n",
        "    u6 = KL.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(a5)\n",
        "    u6 = KL.concatenate([u6, a4])\n",
        "    c6 = KL.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(u6)\n",
        "    n6 = KL.BatchNormalization(axis=3)(c6)\n",
        "    a6 = KL.Activation(\"elu\")(n6)\n",
        "    c6 = KL.Dropout(0.4)(a6)\n",
        "    c6 = KL.Conv2D(256, (3, 3), kernel_initializer='he_normal', padding='same')(c6)\n",
        "    n6 = KL.BatchNormalization(axis=3)(c6)\n",
        "    a6 = KL.Activation(\"elu\")(n6)\n",
        "\n",
        "    u7 = KL.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(a6)\n",
        "    u7 = KL.concatenate([u7, a3])\n",
        "    c7 = KL.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(u7)\n",
        "    n7 = KL.BatchNormalization(axis=3)(c7)\n",
        "    a7 = KL.Activation(\"elu\")(n7)\n",
        "    c7 = KL.Dropout(0.4)(a7)\n",
        "    c7 = KL.Conv2D(128, (3, 3), kernel_initializer='he_normal', padding='same')(c7)\n",
        "    n7 = KL.BatchNormalization(axis=3)(c7)\n",
        "    a7 = KL.Activation(\"elu\")(n7)\n",
        "\n",
        "    u8 = KL.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(a7)\n",
        "    u8 = KL.concatenate([u8, a2])\n",
        "    c8 = KL.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(u8)\n",
        "    n8 = KL.BatchNormalization(axis=3)(c8)\n",
        "    a8 = KL.Activation(\"elu\")(n8)\n",
        "    c8 = KL.Dropout(0.2)(a8)\n",
        "    c8 = KL.Conv2D(64, (3, 3), kernel_initializer='he_normal', padding='same')(c8)\n",
        "    n8 = KL.BatchNormalization(axis=3)(c8)\n",
        "    a8 = KL.Activation(\"elu\")(n8)\n",
        "\n",
        "    u9 = KL.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(a8)\n",
        "    u9 = KL.concatenate([u9, a1], axis=3)\n",
        "    c9 = KL.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(u9)\n",
        "    n9 = KL.BatchNormalization(axis=3)(c9)\n",
        "    a9 = KL.Activation(\"elu\")(n9)\n",
        "    c9 = KL.Dropout(0.2)(a9)\n",
        "    c9 = KL.Conv2D(32, (3, 3), kernel_initializer='he_normal', padding='same')(c9)\n",
        "    n9 = KL.BatchNormalization(axis=3)(c9)\n",
        "    a9 = KL.Activation(\"elu\")(n9)\n",
        "\n",
        "    outputs = KL.Conv2D(1, (1, 1), activation='sigmoid')(a9)\n",
        "    \n",
        "    # Add multi-GPU support.(not tested)\n",
        "    if GPU_COUNT > 1:\n",
        "        with tf.device(\"/cpu:0\"):\n",
        "            model = KM.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "        # make the model parallel\n",
        "        model = KU.training_utils.multi_gpu_model(model, gpus=GPU_COUNT)\n",
        "\n",
        "    else:\n",
        "        model = KM.Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZlcVEhk-N1zY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import imgaug\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def random_crop(image, mask, crop_size = 256):\n",
        "    h, w = image.shape[:2]\n",
        "    y = random.randint(0, (h - crop_size))\n",
        "    x = random.randint(0, (w - crop_size))\n",
        "    img_crop = image[y:y + crop_size, x:x + crop_size]\n",
        "    msk_crop = mask[y:y + crop_size, x:x + crop_size]\n",
        "    return img_crop, msk_crop\n",
        "\n",
        "def data_generator(img_list, msk_list, batch_size=2, crop_size=256, augmentation=None):\n",
        "    \n",
        "    batch_img = np.zeros((batch_size, crop_size, crop_size, 3))\n",
        "    batch_msk = np.zeros((batch_size, crop_size, crop_size, 1))\n",
        "    \n",
        "    image_index = -1\n",
        "    \n",
        "    while True:\n",
        "        for i in range(batch_size):\n",
        "            image_index = (image_index + 1) % len(img_list)\n",
        "            \n",
        "            batch_img[i], batch_msk[i] = random_crop(img_list[image_index],\n",
        "                                                     msk_list[image_index])\n",
        "        \n",
        "        if augmentation:\n",
        "            aug_det = augmentation.to_deterministic()\n",
        "            batch_img = aug_det.augment_images(batch_img)\n",
        "            batch_msk = aug_det.augment_images(batch_msk)\n",
        "\n",
        "        yield batch_img, batch_msk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EoIjwzAVRNBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "crop_size = 256\n",
        "\n",
        "augmentation = imgaug.augmenters.SomeOf((0, 2), [\n",
        "        imgaug.augmenters.Fliplr(0.5),\n",
        "        imgaug.augmenters.Flipud(0.5),\n",
        "        imgaug.augmenters.OneOf([imgaug.augmenters.Affine(rotate=90),\n",
        "                                 imgaug.augmenters.Affine(rotate=180),\n",
        "                                 imgaug.augmenters.Affine(rotate=270)])\n",
        "        #imgaug.augmenters.Multiply((0.8, 1.5)),\n",
        "        #imgaug.augmenters.GaussianBlur(sigma=(0.0, 5.0))\n",
        "])\n",
        "\n",
        "\n",
        "img_train, img_val, gt_train, gt_val = train_test_split(img_list, gt_list, test_size=0.1, random_state=7, shuffle=True)\n",
        "\n",
        "train_generator = data_generator(img_train, gt_train, batch_size=batch_size, crop_size=crop_size, augmentation=augmentation)\n",
        "val_generator   = data_generator(img_val,   gt_val,   batch_size=batch_size, crop_size=crop_size, augmentation=augmentation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UvW3uuhHUqC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "9d2e2279-1336-41e6-a2e0-dac8df11301b"
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from keras.optimizers import Adam, SGD\n",
        "\n",
        "NAME = 'bowl'\n",
        "now = datetime.datetime.now()\n",
        "LOG_DIR = os.path.join(MODEL_DIR, \"{}{:%Y%m%dT%H%M}\".format(NAME.lower(), now))\n",
        "checkpoint_path = os.path.join(LOG_DIR, \"U_net_{epoch:04d}.h5\")\n",
        "\n",
        "#Model\n",
        "model = Unet(crop_size)\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss=bce_dice_loss, metrics=[mean_iou,KLO.binary_crossentropy])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=0, write_graph=True, write_images=False),\n",
        "             keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=0, save_weights_only=True)\n",
        "]\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=len(img_train)/batch_size, epochs=5,\n",
        "                    validation_data=val_generator, validation_steps=len(img_val)/batch_size, initial_epoch=0, callbacks=callbacks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "46/45 [==============================] - 58s 1s/step - loss: -0.2438 - mean_iou: 0.3717 - binary_crossentropy: 0.4790 - val_loss: 4.1003 - val_mean_iou: 0.4276 - val_binary_crossentropy: 8.5873\n",
            "Epoch 2/5\n",
            "46/45 [==============================] - 47s 1s/step - loss: -0.5711 - mean_iou: 0.4295 - binary_crossentropy: 0.2136 - val_loss: 0.2785 - val_mean_iou: 0.4316 - val_binary_crossentropy: 1.2828\n",
            "Epoch 3/5\n",
            "46/45 [==============================] - 47s 1s/step - loss: -0.6951 - mean_iou: 0.4324 - binary_crossentropy: 0.1499 - val_loss: 0.5856 - val_mean_iou: 0.4322 - val_binary_crossentropy: 2.1122\n",
            "Epoch 4/5\n",
            "46/45 [==============================] - 47s 1s/step - loss: -0.7700 - mean_iou: 0.4313 - binary_crossentropy: 0.1177 - val_loss: -0.6759 - val_mean_iou: 0.4321 - val_binary_crossentropy: 0.2668\n",
            "Epoch 5/5\n",
            "19/45 [===========>..................] - ETA: 25s - loss: -0.8094 - mean_iou: 0.4325 - binary_crossentropy: 0.1127"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "46/45 [==============================] - 47s 1s/step - loss: -0.8074 - mean_iou: 0.4325 - binary_crossentropy: 0.1052 - val_loss: -0.6944 - val_mean_iou: 0.4323 - val_binary_crossentropy: 0.1966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89a7c7a0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}